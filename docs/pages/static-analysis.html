<html lang=en>
 <head>
  <meta charset=UTF-8>
  <meta charset=utf-8>
  <title>Static Analysis | Jake Chvatal</title>
  <meta name=viewport
        content="width=device-width,initial-scale=1.0">
  <meta property=og:title
        content="Static Analysis">
  <meta property=og:type content=website>
  <meta property=og:url
        content=https://jake.isnt.online>
  <meta property=og:image
        content="https://avatars0.githubusercontent.com/u/29869612?s=400&amp;u=32e0c272cbfcc32b8e9585f74ce57d197aa14fb0&amp;v=4">
  <meta property=og:site_name
        content="Jake Chvatal">
  <meta name=description content=Hi>
  <meta name=keywords
        content="Static Analysis, webring, programming, languages">
  <meta name=author content="Jake Chvatal">
  <meta name=robots content=follow>
  <meta name=theme-color content=#fff>
  <link rel=icon type=image/x-icon
        href=/favicon.ico>
  <link sizes=180x180 rel=apple-touch-icon
        type=image/png href=/apple-touch-icon.png>
  <link sizes=32x32 rel=icon type=image/png
        href=/favicon-32x32.png>
  <link sizes=16x16 rel=icon type=image/png
        href=/favicon-16x16.png>
  <link rel=manifest href=/site.webmanifest>
  <link rel=stylesheet
        href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/styles/default.min.css>
  <link rel=stylesheet href=/style.css>
  <script src=/lib.js></script>
  <script
          src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/highlight.min.js></script>
  <script>hljs.highlightAll();</script>
 </head>
 <body>
  <div class=site-body id=site-body>
   <div class=sidebar>
    <a href=/index.html> jake.</a><a href=https://isnt.online> ~ </a><span> / </span>
    <a href=/pages/index.html>pages</a><span> / </span><b>Static Analysis</b>
   </div>
   <main>
    <article class=wikipage>
     <h1 class=title-top>Static Analysis</h1>
     <section>
      <h2>scope</h2>
      <ul>
       <li><span> lexical :: every inner level can access its outer levels - widely 
         accepted to be the correct scoping decision.</span>
      </ul>
      <ul>
       <li><span> dynamic :: functions access the latest definition of a local variable - 
         not deducible at compile time level. This means that for some f wth the body x = 
         3, call g, g has x = 3 in scope.</span>
      </ul>
     </section>
     <section>
      <h2>from &quot;history of t&quot;</h2>
      <p><a class=external href=http://www.paulgraham.com/thist.html>
        [http://www.paulgraham.com/thist.html]</a><span>some of these notes are prompted 
        by this</span>
      <p><span>intro functional languages: rabbit (first scheme compiler), 
        sussman/steele lambda papers, FP languages su ch as Hope, Miranda and Scheme. 
        franz lisp? Bliss language - c-level language from CMU?</span>
      <p><span>pdp-10 hack: remove cons cell from freelist, updated freelist, and 
        branching if the freelist was exhauste d to the gc in a single instruction!</span>
      <p><span>premature optimization is bad, no matter what. do not take shortcuts to 
        simplify what is an already well- designed system! One key tip-off phrase is 
        always something of the form, &quot;We&#39;ll throw out all the old cru ft, 
        start over fresh, and just Do Things Right.&quot;</span>
      <p><span>fixnum :: a &#39;fixed number&#39;, or native machine word building a 
        compiler &#39;self-hosted&#39;, or incrementally -- hosting one in another. how 
        is it done?</span>
      <p><span>maclisp on -10 has mark and sweep run on the register set - 
        &quot;bibop&quot; scheme with all objects boxed, and se gregated by type into 
        pages of memory stop and copy garbage collector: Cheney garbage collection 
        algorithm - does bfs of heap to find everythin g. t used Clark algorithm: dfs 
        traversal, uses heap to provide a search stack</span>
      <p><span>can implement mark and sweep with same costs as stop and copy! norman 
        ramsey</span>
      <p><span>&#39;good&#39; schemes use a range of implementations for lambas. 
        depending on what we know about them at compile time. some turn into nothing, 
        some are control flow, some are stack frames, some cause heap allocation. must 
        understand how compiler handles everything, and scheme is built on this lambda 
        structure</span>
      <p><span>lexemes :: construction of lexical meaning underlying words related 
        through inflection. the lemma is one forn of the lexeme standard procedure :: 
        standardized code for a procedure? TODO</span>
      <p><span>compiler implementation as a tree of objects that could link back to 
        their parents? whoah</span>
     </section>
     <section>
      <h2>aaaa</h2>
      <p><span>these things are relatively communicative but i am not sure what they 
        mean</span>
      <p><span>DFA :: data-flow analysis - ? loop-invariant hoisting :: - ?</span>
      <p><span>global register allocation :: - ? global common subexpression elimination 
        :: - ? find two things that are alpha-equivalent then make them a single 
        expression</span>
      <p><span>copy propagation :: - ? induction-variable elimination :: - ?</span>
      <p><span>learn how to do more things with computer graphics! this area sounds 
        super interesting but i do not know much about it.</span>
      <p><span>assemblers :: norman adams. graph structure? linear text scheme? 
        serializing graph to minimize the span f rom jmps to the things they jump to. 
        push and pop vs push and a generational garbage collector</span>
      <p><span>assemblers :: norman adams. graph structure? linear text scheme? 
        serializing graph to minimize the span f rom jmps to the things they jump to.</span>
      <p><span>push and pop vs push and a generational garbage collector</span>
      <p><span>beta-substitution :: - ?</span>
      <p><span>four classic analyses:</span>
      <ul>
       <li><span> go over programs forwards and backwards</span>
      </ul>
      <ul>
       <li><span> unions and intersections</span>
      </ul>
      <ul>
       <li><span>- union, intersection = always, might_possibly</span>
      </ul>
      <p><span>keywords to google</span>
      <ul>
       <li><span> available expressiosn</span>
      </ul>
      <ul>
       <li><span>- forwards intersection</span>
      </ul>
      <ul>
       <li><span> very busy expressions</span>
      </ul>
      <ul>
       <li><span>- backwards intersection</span>
      </ul>
      <ul>
       <li><span> reaching definitions</span>
      </ul>
      <ul>
       <li><span>- forwards union</span>
      </ul>
      <ul>
       <li><span> live variables</span>
      </ul>
      <ul>
       <li><span>- backwards union</span>
      </ul>
     </section>
     <section>
      <h2>specific optimizations</h2>
      <ul>
       <li><span> dead code elimination :: removes code not impacting program results. 
         this shrinks program size and avoids irrelevant operations. this involves code 
         that will never be executed and code that only effects dead variables -- those 
         that are nedver read from again. we can use this as opposed to optional code 
         inclusion via a preprocessor that would perform the same task. much of the dead 
         code this finds is created by other transformations: for example, strength 
         reduction -- we must ensure that the order of analyses is performed in the right 
         way. historically, this is performed using information derived from data-flow 
         analysis with an algorithm based on single assignment form.</span>
      </ul>
      <ul>
       <li><span> dynamic dead code elimination :: some code sections represent dead or 
         unreachable code only under specific conditions. we can accumulate conditions at 
         runtime to determine what processes or loadings to eliminate while we evaluate 
         an expression.</span>
      </ul>
      <ul>
       <li><span> strength reduction :: most of a program&#39;s execution time is spent 
         in a small section of code (the &#39;hot spot&#39;) and that code is inside a 
         loop over and over. the compiler looks to recognize things inside the loop. this 
         records loop invariants: values that do not change within the body of the loop, 
         and induction variables: values iterated each time through the loop. induction 
         variables change by known amounts. we can replace multiplication with successive 
         weaker additions often which is an optimization. we can hoist invariants outside 
         of the loop, such as registers. these are some good examples of strength 
         reduction that can be used: </span><a class=external
        href=https://en.wikipedia.org/wiki/Strength_reduction>
         [https://en.wikipedia.org/wiki/Strength_reduction]</a>
      </ul>
      <ul>
       <li><span> dataflow analysis :: gathering information about values calculated at 
         points during a computer program. set up dataflow equations for each node of the 
         cfg, then solve them by repeatedly calculating the output from the input, 
         locally at each node until a fixpoint is reached -- kildall&#39;s method. </span>
        <a class=external href=https://en.wikipedia.org/wiki/Data-flow_analysis>
         [https://en.wikipedia.org/wiki/Data-flow_analysis]</a>
      </ul>
      <p><span>basic blocks :: - ?</span>
      <p><span>dynamic software updating :: - ?</span>
      <p><span>hot patching :: - ?</span>
      <p><span>maurice wilkes -- helped build the electronic delay storage automatic 
        calculator -- cool guy</span>
      <p><a class=external href=https://en.wikipedia.org/wiki/Loop-invariant_code_motion>
        [Loop-invariant code motion - Wikipedia]</a>
      <p><a class=external
       href=https://h313.info/blog/cpp/security/binary-analysis/2020/11/06/improve-software-debugging-with-binary-analysis.html>
        [Improve Software Debugging with Binary Analysis | some guy’s blog]</a>
      <p><a class=external
       href=https://gist.github.com/jakeisnt/7fa1f054770d52c8d49ccadc524e263e>[Program 
        analysis resources]</a>
     </section>
     <section>
      <h2>Polymorphism</h2>
      <ul>
       <li><span> parametric polymorphism :: allows a function or data type to be written 
         generically so that it can handle values identically without depending on their 
         type these are generic functions, generic datatypes respectively. type of 
         &#39;append&#39; is generic but is *parameratized* with types rank 1.</span>
      </ul>
      <ul>
       <li><span> polymorphism :: type variables cannot be instantiated with polymorphic 
         types.</span>
      </ul>
      <ul>
       <li><span> rank k polymorphism :: rank k polymorphism enforces that the quantifier 
         may not appear ot the left of k or more arrows type inference is decidable for 
         rank 2, but not for rank 3 or above</span>
      </ul>
      <ul>
       <li><span> rank-n polymorphism :: polymorphism in which quantifiers can appear to 
         the left of arbitrarily many arrows</span>
      </ul>
     </section>
    </article>
   </main>
   <div class=git-hist-table>
    <table>
     <tr>
      <th>History
     <tr>
      <td>2022-11-01
      <td><a
       href=https://github.com/jakeisnt/wiki/blob/58a9b56fbfdaae2eee5c07233f96c05fbb50add7//pages/static-analysis.org>
        58a9b56</a>
     <tr>
      <td>2022-11-01
      <td><a
       href=https://github.com/jakeisnt/wiki/blob/b0115e4446dffa45e3135781ca57a3f8bd42fa4c//pages/static-analysis.org>
        b0115e4</a>
     <tr>
      <td>2021-09-22
      <td><a
       href=https://github.com/jakeisnt/wiki/blob/52a677bacbd562f4910a947648a477d5b2ca61e8//pages/static-analysis.org>
        52a677b</a>
     <tr>
      <td>2021-09-21
      <td><a
       href=https://github.com/jakeisnt/wiki/blob/7732812a096dd24427b3086c2ea89d9b0fba4441//pages/static-analysis.org>
        7732812</a>
     <tr>
      <td>2021-08-19
      <td><a
       href=https://github.com/jakeisnt/wiki/blob/87d9551b4dfbc5870468c98d004267f795c5338c//pages/static-analysis.org>
        87d9551</a>
     <tr>
      <td>2021-05-26
      <td><a
       href=https://github.com/jakeisnt/wiki/blob/005a0c7538dd42f310da485f0bb120bf06d8fa5d//pages/static-analysis.org>
        005a0c7</a>
     <tr>
      <td>2021-02-26
      <td><a
       href=https://github.com/jakeisnt/wiki/blob/9ac6ea5932a3b590bf3e33eab2a19bbf987c636c//pages/static-analysis.org>
        9ac6ea5</a>
     <tr>
      <td>2021-02-25
      <td><a
       href=https://github.com/jakeisnt/wiki/blob/8d94bb10dc5371e81b35ea5cf6cb4f0f3e93716b//pages/static-analysis.org>
        8d94bb1</a>
     <tr>
      <td>2021-02-25
      <td><a
       href=https://github.com/jakeisnt/wiki/blob/247b36cc6d7b6ddca0ab2dc8fb5d5c649520b07d//pages/static-analysis.org>
        247b36c</a>
     <tr>
      <td>2021-01-20
      <td><a
       href=https://github.com/jakeisnt/wiki/blob/35e386e55960add42c8fe4635f02dc96c8bb0876//pages/static-analysis.org>
        35e386e</a>
     <tr>
      <td>2020-11-15
      <td><a
       href=https://github.com/jakeisnt/wiki/blob/a0eccac7af6272093d5d2de6398529f411415959//pages/static-analysis.org>
        a0eccac</a>
     
    </table>
   </div>
  </div>
 </body>
</html>